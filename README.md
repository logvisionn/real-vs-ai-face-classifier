# ğŸ§  Real vs AI Face Classifier

ğŸ”— **Live Demo:** [real-vs-ai-face-classifier.onrender.com](https://real-vs-ai-face-classifier.onrender.com)  
ğŸ•’ **Note:** This app is hosted on Renderâ€™s free tier.  
It may take 20â€“30 seconds to wake up on first visit due to cold start.

Deep-learning pipeline that distinguishes **real human faces** from **AI-generated (GAN) faces**.

* ResNet-18 backbone + 2-unit head  
* Grad-CAM visual explanations  
* Temperature-scaled confidence ( *T â‰ˆ 1.7 )  
* Streamlit demo UI  
* One-command Docker deployment  

---

## ğŸ“‘ Table of Contents
1. [Folder Structure](#-folder-structure)
2. [Model Overview](#-model-overview)
3. [Limitation: No Face Detection](#-limitation-no-face-detection)
3. [Performance](#-performance)
4. [Example Grad-CAM](#ï¸-example-grad-cam)
5. [Quick Start](#-quick-start)
6. [Training](#-training)
6. [Notebooks](#-notebooks)  
7. [Environment](#-environment)  
8. [License](#-license)  

---

## ğŸ“‚ Folder Structure
```txt
real-vs-ai-face-classifier/
â”œâ”€â”€ app.py                    # Streamlit web app
â”œâ”€â”€ Dockerfile                # Container recipe
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model_finetuned.pth
â”‚   â””â”€â”€ best_temperature.pt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ gradcam.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ â€¦
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01-data-exploration.ipynb
â”‚   â”œâ”€â”€ 02-gradcam-demo.ipynb
â”‚   â””â”€â”€ 03-temperature-scaling.ipynb
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
````

---

## ğŸ§  Model Overview

| Item             | Details                              |
| ---------------- | ------------------------------------ |
| Backbone         | ResNet-18 (ImageNet weights)         |
| Head             | `AdaptiveAvgPool2d â†’ FC(512, 2)`     |
| Loss / Optimizer | Cross-entropy / Adam (1 e-4)         |
| Training data    | â‰ˆ 380 k faces (Real + StyleGAN/DDPM) |
| Temperature T    | **1.7** (learned on validation set)  |
---

## âš ï¸ Limitation: No Face Detection

This model is a **binary classifier** trained to distinguish between **real** and **AI-generated** *face images*. It **does not verify** whether the input image actually contains a face.

As a result, when uploading **non-face images** (e.g. landscapes, screenshots, objects), the model may still output a prediction like â€œReal â€” 72%â€, because itâ€™s forced to choose between two classes.

â¡ï¸ **Tip:** For best results, upload a clear, frontal face photo.
A future update may include automatic face detection to prevent misclassification on irrelevant inputs.

---


## ğŸ“ˆ Performance

| Dataset / Metric           | Accuracy   |
| -------------------------- | ---------- |
| Standard test split        | **99.2 %** |
| Fine-tuned (hard-real) set | 90.0 %     |
| OOD AI (500)               | 88 %       |
| OOD Real (500)             | 85 %       |

---

## ğŸ–¼ï¸ Example Grad-CAM

| Real Face                                        | AI-Generated                                     |
| ------------------------------------------------ | ------------------------------------------------ |
| <img src="images/real_gradcam.png" width="200"/> | <img src="images/fake_gradcam.png" width="200"/> |

---

## ğŸš€ Quick Start

### 1 Â· Clone the repo

```bash
git clone https://github.com/logvisionn/real-vs-ai-face-classifier.git
cd real-vs-ai-face-classifier
```

### 2 Â· Run locally (Conda)

```bash
conda env create -f environment.yml
conda activate face-classifier
streamlit run app.py
```

### 3 Â· Run with Docker

```bash
docker build -t face-classifier .
docker run -p 8501:8501 face-classifier
# open http://localhost:8501
```

ğŸ“Œ Update weights live (no rebuild):

```bash
docker run -p 8501:8501 -v %cd%/models:/app/models face-classifier
```

---
## ğŸ‹ï¸ Training

1. Place your raw datasets under `data/raw/real/` and `data/raw/ai/`.
2. Preprocess and split them into train/val/test:

```bash
python src/data_preprocessing.py --real-raw data/raw/real --ai-raw data/raw/ai --processed-dir data/processed
```

3. Train the classifier (saves `best_model.pth` under `models/`):

```bash
python src/train.py --data-dir data/processed --output-dir models
```

4. Evaluate a saved model:

```bash
python src/train.py --evaluate-only --data-dir data/processed --output-dir models
```

Optional fineâ€‘tuning on the hardâ€‘real set:

```bash
python src/finetune_hard_real.py --data-dir data/hard_finetune --model-path models/best_model.pth --output-path models/best_model_finetuned.pth
```


---

## ğŸ”¬ Notebooks

| Notebook                   | Purpose                                           |
| -------------------------- | ------------------------------------------------- |
| **01-data-exploration**    | Sample images, class distribution                 |
| **02-gradcam-demo**        | Grad-CAM on mis/correct & OOD faces               |
| **03-temperature-scaling** | Learns scalar *T* and saves `best_temperature.pt` |

---

## ğŸ“¦ Environment

Key packages (full list in `requirements.txt` / `environment.yml`):

* `torch >= 2.0`  Â·  `torchvision`  Â·  `captum`
* `opencv-python-headless`  Â·  `streamlit`  Â·  `scikit-learn`

---

## Â© License

MIT â€” free for personal and commercial use with attribution.

